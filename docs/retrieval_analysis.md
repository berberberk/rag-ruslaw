## Анализ результатов retrieval (BM25 / Dense / Hybrid)

### Краткое сравнение метрик

- **context_recall** показывает, сколько референсных контекстов удалось найти в top-k. Высокий recall говорит о хорошем покрытии, но не гарантирует качество выдачи.
- **context_precision** отражает долю релевантных контекстов среди найденных. При минимальной разметке precision часто ниже recall, особенно для лексических моделей.

### Наблюдения по стратегиям

- **BM25**: стабильная лексическая база. Обычно даёт неплохой recall на юридических текстах за счёт терминов, но precision может проседать из-за «шумных» совпадений.
- **Dense**: за счёт семантики лучше улавливает перефразировки, precision растёт на семантических запросах, но чувствителен к качеству эмбеддингов и чанкинга.
- **Hybrid**: комбинирует сигналы BM25 и Dense. Часто даёт лучший баланс recall/precision, но итог зависит от весов и качества обоих индексов.

### Почему возможен высокий recall и низкий precision

- Чанки длинные и содержат много служебных фрагментов, поэтому совпадения по doc_id/chunk_id легко дают hit (recall), но не все найденные чанки реально полезны (precision).
- Неполная разметка: если gold_chunk_ids не заданы для части вопросов, precision может быть заниженной, а std — завышенной.

### Trade-off’ы по графикам

- Если **context_recall** у Hybrid > BM25, а **context_precision** близок к Dense, это аргумент в пользу гибридного подхода.
- Если Dense сильно проигрывает по precision, стоит проверять модель эмбеддингов или параметры чанкинга (длина, очистка HTML).

### Используемые артефакты

- Таблица сравнения: `reports/tables/retriever_comparison.csv` / `.md`
- Графики: `reports/figures/context_precision.png`, `reports/figures/context_recall.png`

Эти материалы готовы к включению в отчёт без дополнительной обработки.
